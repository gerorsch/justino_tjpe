import os
import traceback
import json
from typing import List, Dict
from sentence_transformers import CrossEncoder
from elasticsearch import Elasticsearch, exceptions as es_exceptions
from preprocessing.sentence_indexing_rag import ElasticsearchSetup
from elasticsearch import Elasticsearch

CLOUD_ID = os.getenv("ELASTIC_CLOUD_ID")          # ex.: "mydeploy:ZGZmLmâ€¦"
API_KEY  = os.getenv("ELASTICSEARCH_API_KEY")    # ex.: "ZXlKMWâ€¦"
HOST     = os.getenv("ELASTICSEARCH_HOST")       # opcional

if CLOUD_ID and API_KEY:
    print(f"ðŸ”Œ retrieval_rerank: usando Elastic Cloud ({CLOUD_ID.split(':',1)[0]})")
    es = Elasticsearch(
        cloud_id=CLOUD_ID,
        api_key=API_KEY,
        headers={"Accept": "application/vnd.elasticsearch+json; compatible-with=8"}
    )
elif HOST:
    print(f"ðŸ”Œ retrieval_rerank: usando host {HOST}")
    es = Elasticsearch(
        HOST,
        headers={"Accept": "application/vnd.elasticsearch+json; compatible-with=8"},
        verify_certs=HOST.startswith("https")
    )
else:
    raise RuntimeError("ðŸ›‘ Defina ELASTIC_CLOUD_ID/API_KEY ou ELASTICSEARCH_HOST")

# Nome do Ã­ndice (use um Ãºnico nome em todo o projeto)
INDEX_NAME = os.getenv("ELASTICSEARCH_INDEX", "sentencas_rag")
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# InstÃ¢ncia lazy do CrossEncoder
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_cross_encoder: CrossEncoder | None = None

def get_cross_encoder() -> CrossEncoder:
    global _cross_encoder
    if _cross_encoder is None:
        rerank_model = os.getenv(
            "RERANK_MODEL",
            "cross-encoder/ms-marco-MiniLM-L-6-v2"
        )
        _cross_encoder = CrossEncoder(rerank_model)
    return _cross_encoder

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FunÃ§Ã£o principal de recuperaÃ§Ã£o
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def recuperar_documentos_similares(
    query: str,
    top_k: int = 10,
    rerank_top_k: int = 5
) -> List[Dict]:
    """
    Executa KNN no Elasticsearch (campo 'embedding' com 3072 dimensÃµes)
    e depois re-rank via CrossEncoder. Retorna lista de dicionÃ¡rios:
      cada dicionÃ¡rio tem: id, relatorio, fundamentacao, dispositivo, score_es, score_rerank.
    """

    try:
        # 1) Cria embedding de 3072 dims usando OpenAI (via ElasticsearchSetup jÃ¡ configurado)
        es_setup = ElasticsearchSetup()
        es_client = es_setup.es
        query_vec = es_setup.create_openai_embedding(query)

        # 2) Monta o body da query KNN para o ES
        knn_body = {
            "size": top_k,
            "knn": {
                "field":        "embedding",
                "query_vector": query_vec,
                "k":            top_k
                # "num_candidates": top_k * 2  # opcional
            }
        }

        # 3) Executa pesquisa KNN no Ã­ndice
        try:
            response = es_client.search(index=INDEX_NAME, body=knn_body)
            hits_list = response.get("hits", {}).get("hits", [])
            if not hits_list:
                return []
            hits = hits_list

        except es_exceptions.TransportError:
            # captura erros de transporte/comunicaÃ§Ã£o com o ES
            traceback.print_exc()
            return []
        except Exception:
            # qualquer outra exceÃ§Ã£o na consulta
            traceback.print_exc()
            return []

        # 4) Monta lista de candidatos, extraindo "relatorio" / "fundamentacao" / "dispositivo"
        candidatos: List[Dict] = []
        for h in hits:
            src = h.get("_source", {})

            # Aqui suponho que seu Ã­ndice tem campos "relatorio", "fundamentacao" e "dispositivo".
            # Caso o nome seja diferente, ajuste para o campo correto.
            candidatos.append({
                "id":            h.get("_id", ""),
                "relatorio":     src.get("relatorio", ""),
                "fundamentacao": src.get("fundamentacao", ""),
                "dispositivo":   src.get("dispositivo", ""),
                "score_es":      float(h.get("_score", 0.0)),
            })

        if not candidatos:
            return []

        # 5) Re-rank via CrossEncoder (usa apenas query + relatorio)
        reranker = get_cross_encoder()
        pares = [(query, c["relatorio"]) for c in candidatos]
        try:
            rerank_scores = reranker.predict(pares)
        except Exception:
            traceback.print_exc()
            return []

        # 6) Anexa pontuaÃ§Ã£o de rerank e ordena
        for c, score in zip(candidatos, rerank_scores):
            c["score_rerank"] = float(score)
        candidatos.sort(key=lambda x: x["score_rerank"], reverse=True)

        # Retorna os top rerankados
        return candidatos[:rerank_top_k]

    except Exception:
        traceback.print_exc()
        return []

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ExecuÃ§Ã£o local para teste (opcional)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    path = os.getenv("RELATORIO_PATH", "relatorio.txt")
    if not os.path.isfile(path):
        print(f"Arquivo '{path}' nÃ£o encontrado.")
        exit(1)

    with open(path, "r", encoding="utf-8") as f:
        query = f.read().strip()

    print(f"â†’ Query carregada de '{path}' ({len(query)} caracteres)\n")
    resultados = recuperar_documentos_similares(query)
    print("=== Resultados Top-Rerank ===")
    print(json.dumps(resultados, ensure_ascii=False, indent=2))
