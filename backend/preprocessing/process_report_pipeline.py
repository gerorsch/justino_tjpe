from __future__ import annotations

import argparse
import os
import re
import sys
import textwrap
from pathlib import Path
from typing import Callable, Dict, List, Optional, Tuple
from dataclasses import dataclass
from types import SimpleNamespace
import hashlib
from concurrent.futures import ThreadPoolExecutor, as_completed
from dotenv import load_dotenv
load_dotenv()

from langchain_community.document_loaders import PyPDFLoader
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.llms.base import BaseLLM
import anthropic
from pypdf.errors import PdfReadError
from pypdf import PdfReader

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@dataclass
class Config:
    summary_model: str = os.getenv("SUMMARY_MODEL", "gpt-4.1-mini")
    report_model:  str = os.getenv("REPORT_MODEL",  "claude-sonnet-4-20250514")
    temperature:   float = float(os.getenv("TEMPERATURE", 0.3))
    max_tokens:    int = int(os.getenv("MAX_TOKENS", 2048))
    fallback_chars:int = int(os.getenv("FALLBACK_CHARS", 10000))
    verbose:       bool  = os.getenv("VERBOSE", "false").lower() in ("1","true","yes","t")

def log(msg: str, cfg: Config):
    if cfg.verbose:
        print(msg, file=sys.stderr)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ detectar peÃ§a â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PIECE_KWS: Dict[str, list[str]] = {
    "peticao_inicial": ["petiÃ§Ã£o inicial", "peticao inicial"],
    "contestacao":     ["contestaÃ§Ã£o", "contestacao"],
    "decisao":         ["decisÃ£o", "decisao"],
    "despacho":        ["despacho"],
    "sentenca":        ["sentenÃ§a", "sentenca"],
    "replica":         ["rÃ©plica", "replica"],
}

def classify_page(txt: str) -> str:
    low = txt.lower()
    for lab, kws in PIECE_KWS.items():
        if any(kw in low for kw in kws):
            return lab
    return "outros"

def extract_process_number(first_page_text: str) -> Optional[str]:
    """
    Extrai o nÃºmero do processo da primeira pÃ¡gina do PDF
    """
    if not first_page_text:
        return None
    
    # PadrÃµes de nÃºmero de processo (ordem de prioridade)
    patterns = [
        # Formato CNJ padrÃ£o: 0000000-00.0000.0.00.0000
        r'\b\d{7}-\d{2}\.\d{4}\.\d{1}\.\d{2}\.\d{4}\b',
        
        # Formato CNJ com mais dÃ­gitos: 0000000000-00.0000.0.00.0000
        r'\b\d{10}-\d{2}\.\d{4}\.\d{1}\.\d{2}\.\d{4}\b',
        
        # Formato antigo: 0000.00.000000-0
        r'\b\d{4}\.\d{2}\.\d{6}-\d{1}\b',
        
        # PadrÃµes com texto: "NÃºmero: 0000000-00.0000.0.00.0000"
        r'(?:nÃºmero|processo|autos)(?:\s*:?\s*|\s+n[ÂºÂ°]?\.?\s*)(\d{7}-\d{2}\.\d{4}\.\d{1}\.\d{2}\.\d{4})',
        
        # PadrÃµes com texto mais genÃ©ricos
        r'(?:processo|autos)(?:\s+n[ÂºÂ°]?\.?\s*|\s+)(\d+[-\.\d]+)',
        
        # PadrÃ£o especÃ­fico do PJe: "Processo EletrÃ´nico nÂº ..."
        r'processo\s+eletr[Ã´o]nico\s+n[ÂºÂ°]?\s*(\d{7}-\d{2}\.\d{4}\.\d{1}\.\d{2}\.\d{4})',
    ]
    
    text_lower = first_page_text.lower()
    
    for i, pattern in enumerate(patterns):
        matches = re.findall(pattern, text_lower, re.IGNORECASE)
        if matches:
            # Para padrÃµes com grupo de captura, pega o grupo
            if i >= 3:  # PadrÃµes com grupos de captura
                number = matches[0] if isinstance(matches[0], str) else matches[0]
            else:  # PadrÃµes diretos
                number = matches[0]
            
            # ValidaÃ§Ã£o adicional para formato CNJ
            if re.match(r'\d{7}-\d{2}\.\d{4}\.\d{1}\.\d{2}\.\d{4}', number):
                return number
            elif re.match(r'\d{10}-\d{2}\.\d{4}\.\d{1}\.\d{2}\.\d{4}', number):
                return number
            elif len(number) > 10:  # Outros formatos longos
                return number
    
    return None

def group_pages(pages: List, cfg: Config) -> tuple[Dict[str, List[str]], Optional[str]]:
    """
    Agrupa pÃ¡ginas por tipo de peÃ§a e extrai nÃºmero do processo da primeira pÃ¡gina
    """
    groups: Dict[str, List[str]] = {}
    cur: Optional[str] = None
    buf: List[str] = []
    process_number = None
    
    for i, p in enumerate(pages):
        # Extrai nÃºmero do processo da primeira pÃ¡gina
        if i == 0:
            process_number = extract_process_number(p.page_content)
            if process_number:
                log(f"ğŸ“‹ NÃºmero do processo identificado: {process_number}", cfg)
            else:
                log("âš ï¸ NÃºmero do processo nÃ£o encontrado na primeira pÃ¡gina", cfg)
        
        lab = classify_page(p.page_content)
        if lab != cur:
            if buf:
                groups.setdefault(cur or "outros", []).append("\n".join(buf))
                buf = []
            cur = lab
            log(f"â†’ nova peÃ§a '{lab}' na pÃ¡gina {i+1}", cfg)
        buf.append(p.page_content)
    
    if buf:
        groups.setdefault(cur or "outros", []).append("\n".join(buf))
    
    return groups, process_number

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ prompts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SUMMARY_PT = PromptTemplate(
    template=textwrap.dedent("""
        Leia o texto e liste **cada ato processual relevante** jÃ¡ no formato:
        â€“ frase concisa (ID 123456789).
        NÃ£o inclua tÃ­tulos como "PetiÃ§Ã£o Inicial".
        Texto:
        {texto}
    """),
    input_variables=["texto"],
)

# Prompt modificado para incluir nÃºmero do processo
INSTRUCOES_COM_PROCESSO = textwrap.dedent("""
    TAREFA
    Elabore um relatÃ³rio analÃ­tico e detalhado do processo judicial fornecido, com base nos documentos constantes dos autos. Utilize estilo direto, informando de maneira objetiva o conteÃºdo de cada ato processual relevante, com a respectiva identificaÃ§Ã£o por ID.

    NÃšMERO DO PROCESSO
    O processo tem o nÃºmero: {numero_processo}

    INSTRUÃ‡Ã•ES ESPECÃFICAS
    - Inicie o relatÃ³rio com "Processo nÂº {numero_processo}"
    - NÃ£o inclua os tÃ­tulos formais das peÃ§as (ex: "PetiÃ§Ã£o Inicial", "Despacho", "DecisÃ£o", etc.).
    - Identifique os atos com uma frase introdutÃ³ria direta e o nÃºmero do ID entre parÃªnteses, como nos exemplos abaixo:
      - Foi concedida a justiÃ§a gratuita (ID 36457517).
      - Tutela de urgÃªncia deferida (ID 37574668).
      - RÃ©plica apresentada (ID 42715461).
    - Ao tratar de manifestaÃ§Ãµes das partes (petiÃ§Ãµes), explique brevemente seu conteÃºdo jurÃ­dico.
    - Na contestaÃ§Ã£o, redija um parÃ¡grafo mais desenvolvido, contendo:
      - Os principais fatos narrados;
      - Os fundamentos jurÃ­dicos alegados;
      - O pedido final;
      - E se foram juntados documentos e procuraÃ§Ãµes.
    - A RÃ©plica deve ser indicada apenas com a frase: "RÃ©plica no ID ___.", sem sÃ­ntese adicional.
    - Inclua todas as petiÃ§Ãµes, exceto as de habilitaÃ§Ã£o de advogado.
    - Ignore todas as certidÃµes, exceto:
      - CertidÃµes de citaÃ§Ã£o positiva;
      - CertidÃµes de decurso de prazo (ex: "decorrido o prazo sem manifestaÃ§Ã£o").

    MODELO DE FORMATAÃ‡ÃƒO DO RELATÃ“RIO
    Processo nÂº {numero_processo}
    
    Vistos, etc.
    NOME DO AUTOR, qualificado na inicial, por intermÃ©dio de advogado legalmente habilitado por instrumento de mandado, propÃ´s AÃ‡ÃƒO EM ITÃLICO contra NOME DO RÃ‰U, tambÃ©m qualificado, com o objetivo de sintetizar o pedido da aÃ§Ã£o em minÃºsculas.
    A parte autora alegou que [...] (ID: ___).
    Foi deferida a gratuidade judiciÃ¡ria (ID: ___).
    Tutela de urgÃªncia concedida [...] (ID: ___).
    ContestaÃ§Ã£o apresentada (ID: ___), na qual a parte rÃ© [...]
    RÃ©plica no ID ___.
    ManifestaÃ§Ã£o da parte autora [...] (ID ___).
    Decurso de prazo certificado (ID ___).
    [Outros atos relevantes, em sequÃªncia cronolÃ³gica].
""")

INSTRUCOES_SEM_PROCESSO = textwrap.dedent("""
    TAREFA
    Elabore um relatÃ³rio analÃ­tico e detalhado do processo judicial fornecido, com base nos documentos constantes dos autos. Utilize estilo direto, informando de maneira objetiva o conteÃºdo de cada ato processual relevante, com a respectiva identificaÃ§Ã£o por ID.

    INSTRUÃ‡Ã•ES ESPECÃFICAS
    - NÃ£o inclua os tÃ­tulos formais das peÃ§as (ex: "PetiÃ§Ã£o Inicial", "Despacho", "DecisÃ£o", etc.).
    - Identifique os atos com uma frase introdutÃ³ria direta e o nÃºmero do ID entre parÃªnteses, como nos exemplos abaixo:
      - Foi concedida a justiÃ§a gratuita (ID 36457517).
      - Tutela de urgÃªncia deferida (ID 37574668).
      - RÃ©plica apresentada (ID 42715461).
    - Ao tratar de manifestaÃ§Ãµes das partes (petiÃ§Ãµes), explique brevemente seu conteÃºdo jurÃ­dico.
    - Na contestaÃ§Ã£o, redija um parÃ¡grafo mais desenvolvido, contendo:
      - Os principais fatos narrados;
      - Os fundamentos jurÃ­dicos alegados;
      - O pedido final;
      - E se foram juntados documentos e procuraÃ§Ãµes.
    - A RÃ©plica deve ser indicada apenas com a frase: "RÃ©plica no ID ___.", sem sÃ­ntese adicional.
    - Inclua todas as petiÃ§Ãµes, exceto as de habilitaÃ§Ã£o de advogado.
    - Ignore todas as certidÃµes, exceto:
      - CertidÃµes de citaÃ§Ã£o positiva;
      - CertidÃµes de decurso de prazo (ex: "decorrido o prazo sem manifestaÃ§Ã£o").

    MODELO DE FORMATAÃ‡ÃƒO DO RELATÃ“RIO
    Vistos, etc.
    NOME DO AUTOR, qualificado na inicial, por intermÃ©dio de advogado legalmente habilitado por instrumento de mandado, propÃ´s AÃ‡ÃƒO EM ITÃLICO contra NOME DO RÃ‰U, tambÃ©m qualificado, com o objetivo de sintetizar o pedido da aÃ§Ã£o em minÃºsculas.
    A parte autora alegou que [...] (ID: ___).
    Foi deferida a gratuidade judiciÃ¡ria (ID: ___).
    Tutela de urgÃªncia concedida [...] (ID: ___).
    ContestaÃ§Ã£o apresentada (ID: ___), na qual a parte rÃ© [...]
    RÃ©plica no ID ___.
    ManifestaÃ§Ã£o da parte autora [...] (ID ___).
    Decurso de prazo certificado (ID ___).
    [Outros atos relevantes, em sequÃªncia cronolÃ³gica].
""")

REPORT_PT = PromptTemplate(
    template="""{instr}

CONTEÃšDO DOS AUTOS:
{linhas_atos}

RELATÃ“RIO:""",
    input_variables=["instr", "linhas_atos"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ wrapper Claude CORRIGIDO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AnthropicClaudeWrapper:
    def __init__(self, model: str, max_tokens: int = 2048, temperature: float = 0.3):
        self.client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        self.model = model
        self.max_tokens = max_tokens
        self.temperature = temperature

    def _extract_text_from_response(self, response_content) -> str:
        """
        Extrai o texto da resposta do Claude de forma segura.
        A API do Anthropic retorna response.content como uma lista de TextBlocks.
        """
        if not response_content:
            return ""
        
        if isinstance(response_content, str):
            # Se jÃ¡ Ã© string, retorna diretamente
            return response_content
        
        if isinstance(response_content, list):
            # Se Ã© lista de TextBlocks, extrai o texto de cada um
            text_parts = []
            for block in response_content:
                if hasattr(block, 'text'):
                    # Objeto TextBlock com atributo text
                    text_parts.append(block.text)
                elif isinstance(block, dict) and 'text' in block:
                    # DicionÃ¡rio com chave text
                    text_parts.append(block['text'])
                elif isinstance(block, str):
                    # String direta
                    text_parts.append(block)
                else:
                    # Fallback: converte para string
                    text_parts.append(str(block))
            
            return ''.join(text_parts)
        
        # Fallback final: converte para string
        return str(response_content)

    def invoke(self, input_data: dict) -> str:
        user_msg = input_data.get("prompt") or (
            input_data["instr"]
            + "\n\nCONTEÃšDO DOS AUTOS:\n"
            + input_data["linhas_atos"]
            + "\n\nRELATÃ“RIO:"
        )
        
        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                messages=[{"role": "user", "content": user_msg}],
            )
            
            # CORREÃ‡ÃƒO: Extrai o texto corretamente da resposta do Claude
            text = self._extract_text_from_response(response.content)
            return text.strip()
            
        except Exception as e:
            print(f"Erro na chamada da API Anthropic: {e}", file=sys.stderr)
            return f"Erro na geraÃ§Ã£o de conteÃºdo: {str(e)}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ funÃ§Ãµes LLM CORRIGIDAS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _extract_text_safely(response) -> str:
    """
    FunÃ§Ã£o auxiliar para extrair texto de respostas de LLM de forma segura.
    Funciona tanto para responses do Claude quanto do OpenAI.
    """
    if not response:
        return ""
    
    # Se tem atributo content
    if hasattr(response, "content"):
        content = response.content
        
        if isinstance(content, str):
            return content
        elif isinstance(content, list):
            # Lista de TextBlocks (Claude)
            text_parts = []
            for block in content:
                if hasattr(block, 'text'):
                    text_parts.append(block.text)
                elif isinstance(block, dict) and 'text' in block:
                    text_parts.append(block['text'])
                elif isinstance(block, str):
                    text_parts.append(block)
                else:
                    text_parts.append(str(block))
            return ''.join(text_parts)
        else:
            return str(content)
    
    # Se Ã© string direta
    if isinstance(response, str):
        return response
    
    # Fallback final
    return str(response)

def get_llm(model: str, cfg: Config):
    use_claude = os.getenv("USE_CLAUDE_FOR_REPORT", "false").lower() in ("1", "true", "yes", "t")
    if use_claude and model.startswith("claude"):
        return AnthropicClaudeWrapper(model=model, max_tokens=cfg.max_tokens, temperature=cfg.temperature)
    else:
        return ChatOpenAI(model_name=model, temperature=cfg.temperature, max_tokens=cfg.max_tokens)

def summarize(text: str, llm: BaseLLM, cfg: Config) -> str:
    try:
        resp = (SUMMARY_PT | llm).invoke({"texto": text})
        content = _extract_text_safely(resp)
        return content.strip()
    except Exception as e:
        print(f"Erro na funÃ§Ã£o summarize: {e}", file=sys.stderr)
        return f"Documento processado com {len(text)} caracteres."


def build_report(atos: str, process_number: Optional[str], cfg: Config) -> str:
    """
    ConstrÃ³i o relatÃ³rio final, incluindo nÃºmero do processo se disponÃ­vel
    """
    try:
        llm = get_llm(cfg.report_model, cfg)
        
        # Escolhe as instruÃ§Ãµes corretas baseado na disponibilidade do nÃºmero do processo
        if process_number:
            instructions = INSTRUCOES_COM_PROCESSO.format(numero_processo=process_number)
        else:
            instructions = INSTRUCOES_SEM_PROCESSO
        
        formatted_prompt = REPORT_PT.format(instr=instructions, linhas_atos=atos)
        
        if hasattr(llm, "invoke"):
            resp = llm.invoke({"prompt": formatted_prompt})
        else:
            resp = llm.predict(formatted_prompt)
        
        # CORREÃ‡ÃƒO: Usa funÃ§Ã£o auxiliar para extrair texto de forma segura
        content = _extract_text_safely(resp)
        
        # Se temos nÃºmero do processo mas ele nÃ£o aparece no inÃ­cio do relatÃ³rio, adiciona
        if process_number and not content.strip().startswith(f"Processo nÂº {process_number}"):
            content = f"Processo nÂº {process_number}\n\n{content.strip()}"
        
        return content.strip()
    
    except Exception as e:
        print(f"Erro na funÃ§Ã£o build_report: {e}", file=sys.stderr)
        # Retorna um relatÃ³rio bÃ¡sico em caso de erro
        if process_number:
            return f"Processo nÂº {process_number}\n\nRelatÃ³rio: Processo analisado com base nos atos processuais fornecidos.\n\n{atos}"
        else:
            return f"RelatÃ³rio: Processo analisado com base nos atos processuais fornecidos.\n\n{atos}"

def clean_textblock_artifacts(text: str) -> str:
    """
    Remove resÃ­duos de TextBlock que possam aparecer no texto final.
    """
    if not text:
        return ""
    
    # Remove padrÃµes como "TextBlock(citations=None, text="
    text = re.sub(r'TextBlock\([^)]*\)', '', text)
    
    # Remove padrÃµes como "[TextBlock(citations=None, text="...")]"
    text = re.sub(r'\[TextBlock\([^]]*\)\]', '', text)
    
    # Remove "citations=None, text=" e variaÃ§Ãµes
    text = re.sub(r'citations=None,\s*text=', '', text)
    text = re.sub(r'citations=[^,]*,\s*text=', '', text)
    text = re.sub(r"type='text'", '', text)
    
    # Remove aspas extras no inÃ­cio/fim
    text = text.strip('"\'')
    
    # Remove quebras de linha excessivas
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    return text.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ geraÃ§Ã£o principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate(
    pdf: Path,
    cfg: Config,
    on_progress: Optional[Callable[[str], None]] = None
) -> str:
    summary_llm = get_llm(cfg.summary_model, cfg)
    # â”€â”€ CACHE: se jÃ¡ houver relatÃ³rio para este PDF, retorna imediatamente

    digest = hashlib.sha256(pdf.read_bytes()).hexdigest()
    cache_path = Path(f"/tmp/report_{digest}.txt")
    if cache_path.exists():
        log("â™»ï¸  Usando relatÃ³rio em cache", cfg)
        return cache_path.read_text(encoding="utf-8")
    try:
        # 1) Carrega o PDF, com fallback em caso de PdfReadError
        try:
            pages = PyPDFLoader(str(pdf)).load()
        except PdfReadError as e:
            log(f"âš ï¸ PyPDFLoader falhou ({e}), usando fallback com PdfReader(strict=False)", cfg)
            reader = PdfReader(str(pdf), strict=False)
            pages = []
            for idx, page in enumerate(reader.pages, start=1):
                try:
                    text = page.extract_text() or ""
                except PdfReadError:
                    log(f"   â€“ erro extraindo texto da pÃ¡gina {idx}, pulando conteÃºdo", cfg)
                    text = ""
                pages.append(SimpleNamespace(page_content=text))

        # progresso inicial
        msg = f"ğŸ“„ PDF com {len(pages)} pÃ¡ginas carregado"
        log(msg, cfg)
        if on_progress:
            on_progress(msg)

        # 2) Agrupa por peÃ§a e extrai nÃºmero do processo
        grupos, process_number = group_pages(pages, cfg)
        
        if process_number:
            log(f"âœ… Processo identificado: {process_number}", cfg)
            if on_progress:
                on_progress(f"ğŸ“‹ Processo nÂº {process_number} identificado")

        # 3) LÃª e resume chunks
        linhas: List[str] = []

        # 1) Primeiro, monte a lista de (label, texto) a resumir
        chunks_para_resumir: List[Tuple[str, str]] = []
        for label, blocos in grupos.items():
            sec_msg = f"ğŸ” Lendo seÃ§Ã£o '{label}' ({len(blocos)} chunks)"
            log(sec_msg, cfg)
            if on_progress:
                on_progress(sec_msg)

            # Junta todos os blocos da seÃ§Ã£o
            texto_secao = "\n".join(blocos)

            # Se for muito grande, divide em sub-chunks grandes
            if len(texto_secao) > cfg.fallback_chars:
                parts = [
                    texto_secao[i : i + cfg.fallback_chars]
                    for i in range(0, len(texto_secao), cfg.fallback_chars)
                ]
            else:
                parts = [texto_secao]

            # Registra cada parte para resumir depois
            for pi, part in enumerate(parts, start=1):
                if len(parts) > 1:
                    sub_msg = f"   â†³ subchunk {pi}/{len(parts)}"
                    log(sub_msg, cfg)
                    if on_progress:
                        on_progress(sub_msg)
                chunks_para_resumir.append((label, part))

        # 2) Agora, faÃ§a efetivamente menos chamadas ao LLM
        # (supondo que vocÃª jÃ¡ tenha summary_llm = get_llm(...) criado fora)
       # 2) Paraleliza chamadas de resumo
        # (substitui o loop sequencial por ThreadPoolExecutor)

        def _job(label_text):
            label, texto = label_text
            # use summary_llm diretamente (ou adapte summarize to accept llm)
            resumo = summary_llm.predict(texto)
            return clean_textblock_artifacts(resumo)

        with ThreadPoolExecutor(max_workers=4) as pool:
            futures = { pool.submit(_job, lt): lt for lt in chunks_para_resumir }
            for fut in as_completed(futures):
                linhas.append(fut.result())

        # 3) Concatena tudo para gerar o report
        atos = "\n".join(linhas)

        # 4) ConstruÃ§Ã£o do relatÃ³rio final
        start_msg = "âš™ï¸ Construindo relatÃ³rio final..."
        log(start_msg, cfg)
        if on_progress:
            on_progress(start_msg)
        
        # Passa o nÃºmero do processo para o build_report
        report = build_report(atos, process_number, cfg)
        
        # LIMPEZA FINAL: Remove qualquer artefato de TextBlock restante
        report_limpo = clean_textblock_artifacts(report)
        cache_path.write_text(report_limpo, encoding="utf-8")
        
        done_msg = "âœ… RelatÃ³rio pronto"
        log(done_msg, cfg)
        if on_progress:
            on_progress(done_msg)

        return report_limpo
    
    except Exception as e:
        error_msg = f"Erro na geraÃ§Ã£o do relatÃ³rio: {str(e)}"
        print(error_msg, file=sys.stderr)
        if on_progress:
            on_progress(f"âŒ {error_msg}")
        # Retorna um relatÃ³rio bÃ¡sico em caso de erro total
        return f"Erro no processamento: {str(e)}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    ap = argparse.ArgumentParser(
        description="RelatÃ³rio analÃ­tico peÃ§a-aware (dual-model com suporte ao Claude)"
    )
    ap.add_argument("pdf", type=Path)
    ap.add_argument("-o", "--output", type=Path)
    ap.add_argument("--quiet", action="store_true")
    args = ap.parse_args()

    cfg = Config(verbose=not args.quiet)
    rel = generate(args.pdf, cfg)

    if args.output:
        args.output.write_text(rel, encoding="utf-8")
        log(f"RelatÃ³rio salvo em {args.output}", cfg)
    else:
        print(rel)